{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:33:01.230489Z",
     "start_time": "2019-05-27T10:33:01.225863Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"This is a sentence for trying unigram,bigrams creation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:33:17.150916Z",
     "start_time": "2019-05-27T10:33:16.035823Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:33:50.005550Z",
     "start_time": "2019-05-27T10:33:49.905005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'is'),\n",
       " ('is', 'a'),\n",
       " ('a', 'sentence'),\n",
       " ('sentence', 'for'),\n",
       " ('for', 'trying'),\n",
       " ('trying', 'unigram'),\n",
       " ('unigram', ','),\n",
       " (',', 'bigrams'),\n",
       " ('bigrams', 'creation'),\n",
       " ('creation', '.')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(word_tokenize(text), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:34:13.664684Z",
     "start_time": "2019-05-27T10:34:13.655842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('T', 'h'),\n",
       " ('h', 'i'),\n",
       " ('i', 's'),\n",
       " ('s', ' '),\n",
       " (' ', 'i'),\n",
       " ('i', 's'),\n",
       " ('s', ' '),\n",
       " (' ', 'a'),\n",
       " ('a', ' '),\n",
       " (' ', 's'),\n",
       " ('s', 'e'),\n",
       " ('e', 'n'),\n",
       " ('n', 't'),\n",
       " ('t', 'e'),\n",
       " ('e', 'n'),\n",
       " ('n', 'c'),\n",
       " ('c', 'e'),\n",
       " ('e', ' '),\n",
       " (' ', 'f'),\n",
       " ('f', 'o'),\n",
       " ('o', 'r'),\n",
       " ('r', ' '),\n",
       " (' ', 't'),\n",
       " ('t', 'r'),\n",
       " ('r', 'y'),\n",
       " ('y', 'i'),\n",
       " ('i', 'n'),\n",
       " ('n', 'g'),\n",
       " ('g', ' '),\n",
       " (' ', 'u'),\n",
       " ('u', 'n'),\n",
       " ('n', 'i'),\n",
       " ('i', 'g'),\n",
       " ('g', 'r'),\n",
       " ('r', 'a'),\n",
       " ('a', 'm'),\n",
       " ('m', ','),\n",
       " (',', 'b'),\n",
       " ('b', 'i'),\n",
       " ('i', 'g'),\n",
       " ('g', 'r'),\n",
       " ('r', 'a'),\n",
       " ('a', 'm'),\n",
       " ('m', 's'),\n",
       " ('s', ' '),\n",
       " (' ', 'c'),\n",
       " ('c', 'r'),\n",
       " ('r', 'e'),\n",
       " ('e', 'a'),\n",
       " ('a', 't'),\n",
       " ('t', 'i'),\n",
       " ('i', 'o'),\n",
       " ('o', 'n'),\n",
       " ('n', '.')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(text, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:18:36.393601Z",
     "start_time": "2019-05-27T10:18:36.332051Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "names_df = pd.read_csv(\"nepali_names.csv\",sep = \"\\t\")\n",
    "\n",
    "names_df=names_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "rough_words_df = pd.read_csv(\"rough_words.csv\",sep = \"\\t\")\n",
    "\n",
    "rough_words_df=rough_words_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "possible_text_df = pd.read_csv(\"possible_text_entry.csv\",sep = \"\\t\")\n",
    "\n",
    "possible_text_df=possible_text_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "english_typed_nepali_df = pd.read_csv(\"english_typed_nepali_word.csv\",sep=\"\\t\")\n",
    "\n",
    "english_typed_nepali_df=english_typed_nepali_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "nepali_chat_df = pd.read_csv(\"nepali_chat_text.csv\",sep=\"\\t\")\n",
    "\n",
    "nepali_chat_df=nepali_chat_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "nepali_chat_df = nepali_chat_df[33000:]\n",
    "\n",
    "\n",
    "non_name_df_list = [rough_words_df,possible_text_df,nepali_chat_df,english_typed_nepali_df]\n",
    "non_name_df = pd.concat(non_name_df_list)\n",
    "\n",
    "\n",
    "\n",
    "final_df = names_df.append(non_name_df, ignore_index=True)\n",
    "\n",
    "final_df=final_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:18:36.974519Z",
     "start_time": "2019-05-27T10:18:36.971401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23782, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:18:37.599145Z",
     "start_time": "2019-05-27T10:18:37.595277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TEXT     object\n",
       "LABEL    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:18:38.210689Z",
     "start_time": "2019-05-27T10:18:38.203139Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TEXT     0\n",
       "LABEL    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:18:38.769860Z",
     "start_time": "2019-05-27T10:18:38.763528Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sonim Kumar</td>\n",
       "      <td>NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dayaram</td>\n",
       "      <td>NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dendi Aditya</td>\n",
       "      <td>NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Upadhya Jung</td>\n",
       "      <td>NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abhash Aditya</td>\n",
       "      <td>NAME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TEXT LABEL\n",
       "0    Sonim Kumar  NAME\n",
       "1        Dayaram  NAME\n",
       "2   Dendi Aditya  NAME\n",
       "3   Upadhya Jung  NAME\n",
       "4  Abhash Aditya  NAME"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:18:39.264652Z",
     "start_time": "2019-05-27T10:18:39.259267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(final_df[\"TEXT\"][255])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:01:05.589214Z",
     "start_time": "2019-05-27T10:01:05.415352Z"
    }
   },
   "source": [
    "final_df[\"TEXT\"] = final_df[\"TEXT\"].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:18:41.460388Z",
     "start_time": "2019-05-27T10:18:41.450962Z"
    }
   },
   "outputs": [],
   "source": [
    "final_df.loc[:,\"TEXT\"] = final_df.TEXT.apply(lambda x : str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:18:41.878679Z",
     "start_time": "2019-05-27T10:18:41.867357Z"
    }
   },
   "outputs": [],
   "source": [
    "final_df.loc[:,\"TEXT\"] = final_df.TEXT.apply(lambda x : str.lower(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:18:45.302186Z",
     "start_time": "2019-05-27T10:18:45.291202Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in final_df[\"TEXT\"]:\n",
    "    if type(i)!=str:\n",
    "        print(\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:18:47.475389Z",
     "start_time": "2019-05-27T10:18:47.467412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sonim kumar</td>\n",
       "      <td>NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dayaram</td>\n",
       "      <td>NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dendi aditya</td>\n",
       "      <td>NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>upadhya jung</td>\n",
       "      <td>NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abhash aditya</td>\n",
       "      <td>NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sadashyaharuprati</td>\n",
       "      <td>NOTNAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>surakshit man</td>\n",
       "      <td>NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sudep bachu ayohrishab</td>\n",
       "      <td>NOTNAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bishowram</td>\n",
       "      <td>NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rohin</td>\n",
       "      <td>NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>diwakar</td>\n",
       "      <td>NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bhanne</td>\n",
       "      <td>NOTNAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>candai</td>\n",
       "      <td>NOTNAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>taranga</td>\n",
       "      <td>NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>johnson chandra</td>\n",
       "      <td>NAME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      TEXT    LABEL\n",
       "0              sonim kumar     NAME\n",
       "1                  dayaram     NAME\n",
       "2             dendi aditya     NAME\n",
       "3             upadhya jung     NAME\n",
       "4            abhash aditya     NAME\n",
       "5        sadashyaharuprati  NOTNAME\n",
       "6            surakshit man     NAME\n",
       "7   sudep bachu ayohrishab  NOTNAME\n",
       "8                bishowram     NAME\n",
       "9                    rohin     NAME\n",
       "10                 diwakar     NAME\n",
       "11                  bhanne  NOTNAME\n",
       "12                  candai  NOTNAME\n",
       "13                 taranga     NAME\n",
       "14         johnson chandra     NAME"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:18:49.022532Z",
     "start_time": "2019-05-27T10:18:49.019109Z"
    }
   },
   "outputs": [],
   "source": [
    "final_df[\"TEXT\"] = final_df[\"TEXT\"][0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:18:51.264939Z",
     "start_time": "2019-05-27T10:18:51.259303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15                        sumin\n",
       "16               hansha bahadur\n",
       "17                      trideep\n",
       "18                       tansen\n",
       "19            oye pulchowk xams\n",
       "20    padhya xaina dabhijeet ke\n",
       "21                   kabita man\n",
       "22                  min chandra\n",
       "23                     adhikrit\n",
       "24                       uttano\n",
       "Name: TEXT, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"TEXT\"][15:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:18:52.866252Z",
     "start_time": "2019-05-27T10:18:52.859246Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df[\"TEXT\"], final_df[\"LABEL\"], \n",
    "                                                    test_size=.33, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:18:53.815046Z",
     "start_time": "2019-05-27T10:18:53.787693Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-53a3e5ed6a05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvocabulary_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moov_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'UNK'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TEXT\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TEXT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/infodevai/lib/python3.7/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mfit_on_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    221\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                                             self.split)\n\u001b[0m\u001b[1;32m    224\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_counts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/infodevai/lib/python3.7/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mtext_to_word_sequence\u001b[0;34m(text, filters, lower, split)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "vocabulary_size = 2000\n",
    "tokenizer = Tokenizer(char_level=False, oov_token='UNK',num_words = vocabulary_size)\n",
    "tokenizer.fit_on_texts(final_df[\"TEXT\"])\n",
    "sequences = tokenizer.texts_to_sequences(final_df['TEXT'])\n",
    "data = pad_sequences(sequences,maxlen = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:17:50.757812Z",
     "start_time": "2019-05-27T10:17:47.891Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:17:50.758622Z",
     "start_time": "2019-05-27T10:17:47.894Z"
    }
   },
   "outputs": [],
   "source": [
    "final_df[\"LABEL\"] = final_df[\"LABEL\"].replace([\"NAME\" , \"NOTNAME\",\" NOTNAME\"] , [1 , 0 , 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:17:50.759413Z",
     "start_time": "2019-05-27T10:17:47.897Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = final_df[\"LABEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:17:50.760249Z",
     "start_time": "2019-05-27T10:17:47.899Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense,  LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "import numpy as np\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:17:50.761086Z",
     "start_time": "2019-05-27T10:17:47.903Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(41, 50, input_length=20))\n",
    "model2.add(LSTM(50, dropout=0.2, recurrent_dropout=0.2))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.4))\n",
    "model2.add(Dense(50, activation=\"tanh\"))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.4))\n",
    "model2.add(Dense(50, activation=\"tanh\"))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.4))\n",
    "model2.add(Dense(1, activation=\"sigmoid\"))\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.fit(data, np.array(labels), validation_split=0.4, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:17:50.761992Z",
     "start_time": "2019-05-27T10:17:47.906Z"
    }
   },
   "outputs": [],
   "source": [
    "### Sample prediction\n",
    "text1 = \"mula\"\n",
    "text= np.array([text1])\n",
    "text= tokenizer.texts_to_sequences(text)\n",
    "text = pad_sequences(text, maxlen=50)\n",
    "prediction = model2.predict(text)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:17:50.762885Z",
     "start_time": "2019-05-27T10:17:47.908Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:17:50.763718Z",
     "start_time": "2019-05-27T10:17:47.911Z"
    }
   },
   "outputs": [],
   "source": [
    "test = test_df[\"text\"]\n",
    "test_label = test_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:17:50.764539Z",
     "start_time": "2019-05-27T10:17:47.914Z"
    }
   },
   "outputs": [],
   "source": [
    "sequences_test = tokenizer.texts_to_sequences(test)\n",
    "test_data = pad_sequences(sequences_test,maxlen = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:17:50.765400Z",
     "start_time": "2019-05-27T10:17:47.917Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pred = model2.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:17:50.766232Z",
     "start_time": "2019-05-27T10:17:47.919Z"
    }
   },
   "outputs": [],
   "source": [
    "new_pred = []\n",
    "for i in test_pred:\n",
    "    if i>0.5:\n",
    "        new_pred.append(\"NAME\")\n",
    "    else:\n",
    "        new_pred.append(\"NOTNAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:17:50.767185Z",
     "start_time": "2019-05-27T10:17:47.922Z"
    }
   },
   "outputs": [],
   "source": [
    "result = [(i,j)for i,j in zip(test,new_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:17:50.768125Z",
     "start_time": "2019-05-27T10:17:47.925Z"
    }
   },
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:17:50.769135Z",
     "start_time": "2019-05-27T10:17:47.928Z"
    }
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:17:50.770220Z",
     "start_time": "2019-05-27T10:17:47.931Z"
    }
   },
   "outputs": [],
   "source": [
    "new_pred = []\n",
    "for i in prediction:\n",
    "    if i>0.5:\n",
    "        new_pred.append(\"NAME\")\n",
    "        print(i, new)\n",
    "    else:\n",
    "        new_pred.append(\"NOTNAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:17:50.771327Z",
     "start_time": "2019-05-27T10:17:47.934Z"
    }
   },
   "outputs": [],
   "source": [
    "result = [(i,j)for i,j in zip(new_pred,new)]\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
